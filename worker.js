const { google } = require("googleapis");
const path = require("path");

// Import config ƒë·ªÉ ƒë·ªìng b·ªô v·ªõi index.js
const { config } = require("./config");

/*
 * ======================================================================================
 * MANIFEST WORKER - ƒê·ªìng b·ªô ho√†n ch·ªânh (Folders + Images)
 * 
 * Vai tr√≤ m·ªõi:
 * - ƒê·ªìng b·ªô folder structure v√†o PostgreSQL
 * - ƒê·ªìng b·ªô ·∫£nh v√†o PostgreSQL
 * - T·∫•t c·∫£ trong 1 b∆∞·ªõc duy nh·∫•t
 * ======================================================================================
 */

// C·∫•u h√¨nh t·ª´ config (ƒë·ªìng b·ªô v·ªõi index.js)
const ROOT_FOLDER_ID = config.googleDrive.rootFolderId;
const CHUNK_SIZE = 500; // Gi·∫£m chunk size ƒë·ªÉ tr√°nh timeout
const MAX_DOCUMENT_SIZE = 900 * 1024; // 900KB ƒë·ªÉ an to√†n
const BATCH_LIMIT = 250; // Gi·∫£m batch limit ƒë·ªÉ tr√°nh timeout

// PostgreSQL System State Service
const SystemStateService = require('./src/services/SystemStateService');

// Google Drive API (ƒë·ªìng b·ªô v·ªõi index.js)
let auth;
try {
  if (process.env.GOOGLE_SERVICE_ACCOUNT_EMAIL && process.env.GOOGLE_PRIVATE_KEY) {
    auth = new google.auth.GoogleAuth({
      credentials: {
        client_email: process.env.GOOGLE_SERVICE_ACCOUNT_EMAIL,
        private_key: process.env.GOOGLE_PRIVATE_KEY.replace(/\\n/g, '\n'),
      },
      scopes: config.googleDrive.scopes,
    });
  } else if (config.googleDrive.serviceAccountPath) {
    const serviceAccountPath = path.resolve(config.googleDrive.serviceAccountPath);
    auth = new google.auth.GoogleAuth({
      keyFile: serviceAccountPath,
      scopes: config.googleDrive.scopes,
    });
  } else {
    throw new Error('No Google Drive credentials found');
  }
} catch (error) {
  console.error('‚ùå Worker: Failed to initialize Google Drive auth:', error);
  process.exit(1);
}

const drive = google.drive({ version: "v3", auth });

// =========================
// QU√âT DRIVE V√Ä ƒê·ªíNG B·ªò HO√ÄN CH·ªàNH
// =========================

// Li·ªát k√™ file theo query (c√≥ ph√¢n trang)
async function listByQuery(q, fields = "files(id,name,mimeType,parents,createdTime,thumbnailLink),nextPageToken", pageSize = 1000) {
  let out = [];
  let pageToken = null;
  do {
    const resp = await drive.files.list({
      q,
      fields,
      pageSize,
      pageToken,
      supportsAllDrives: true,
      includeItemsFromAllDrives: true,
    });
    out = out.concat(resp.data.files || []);
    pageToken = resp.data.nextPageToken || null;
  } while (pageToken);
  return out;
}

// L·∫•y th·ªùi gian c·∫≠p nh·∫≠t cu·ªëi c√πng t·ª´ system state (PostgreSQL)
async function getLastUpdateTime() {
  try {
    console.log('üîç [Worker] Getting last update time from PostgreSQL...');
    const data = await SystemStateService.getDocument('manifest_state');
    
    if (data && data.lastProcessed) {
      const lastProcessed = new Date(data.lastProcessed);
      console.log(`üìÖ [Worker] Last processed time: ${lastProcessed.toISOString()}`);
      return lastProcessed;
    }
    
    console.log('üìÖ [Worker] No previous processing time found, starting from beginning');
    return new Date(0); // L·∫ßn ƒë·∫ßu ch·∫°y
  } catch (error) {
    console.error('‚ùå [Worker] Error getting last update time from PostgreSQL:', error);
    // Fallback to Firestore for compatibility
    try {
      console.log('üîÑ [Worker] Falling back to Firestore...');
      const doc = await SYS_STATE_COL.doc('manifest_state').get();
      if (doc.exists) {
        const data = doc.data();
        if (data.lastProcessed) {
          return data.lastProcessed.toDate ? data.lastProcessed.toDate() : new Date(data.lastProcessed);
        }
      }
    } catch (firestoreError) {
      console.error('‚ùå [Worker] Firestore fallback also failed:', firestoreError);
    }
    console.log('‚ö†Ô∏è Using default time (epoch)');
    return new Date(0);
  }
}

// Qu√©t to√†n b·ªô Drive v√† ph√¢n lo·∫°i (folders + images)
async function scanDriveComplete(lastUpdateTime, forceFullScan = false) {
  console.log('üîÑ B·∫Øt ƒë·∫ßu qu√©t to√†n b·ªô Drive...');
  if (forceFullScan) {
    console.log('üîÑ Ch·∫ø ƒë·ªô qu√©t to√†n b·ªô (b·ªè qua th·ªùi gian)');
  } else {
    console.log('üîÑ Ch·∫ø ƒë·ªô qu√©t ·∫£nh m·ªõi t·ª´:', lastUpdateTime.toISOString());
  }
  
  const FOLDER_MIME = "application/vnd.google-apps.folder";
  const allFolders = [];
  const allImages = [];
  const queue = [ROOT_FOLDER_ID];

  while (queue.length) {
    const folderId = queue.shift();

    // 1) ·∫¢nh trong folder hi·ªán t·∫°i (m·ªõi ho·∫∑c t·∫•t c·∫£ t√πy theo mode)
    let imageQuery = `'${folderId}' in parents and trashed=false and (` +
      `mimeType='image/jpeg' or mimeType='image/png' or mimeType='image/webp')`;
    
    if (!forceFullScan) {
      imageQuery += ` and createdTime > '${lastUpdateTime.toISOString()}'`;
    }
    
    const imgs = await listByQuery(
      imageQuery,
      "files(id,name,createdTime,parents,mimeType,thumbnailLink),nextPageToken"
    );
    allImages.push(...imgs);

    // 2) T·∫•t c·∫£ folders (kh√¥ng ph√¢n bi·ªát m·ªõi/c≈©)
    const folders = await listByQuery(
      `'${folderId}' in parents and trashed=false and mimeType='${FOLDER_MIME}'`,
      "files(id,name,createdTime,parents),nextPageToken"
    );
    
    // Th√™m v√†o danh s√°ch folders
    allFolders.push(...folders);
    
    // Th√™m v√†o queue ƒë·ªÉ duy·ªát ti·∫øp
    folders.forEach(f => queue.push(f.id));
  }

  console.log(`‚úÖ Qu√©t ho√†n th√†nh:`);
  console.log(`   - üìÅ Folders: ${allFolders.length}`);
  if (forceFullScan) {
    console.log(`   - üñºÔ∏è T·ªïng ·∫£nh: ${allImages.length}`);
  } else {
    console.log(`   - üñºÔ∏è ·∫¢nh m·ªõi: ${allImages.length}`);
  }
  
  return { allFolders, allImages };
}

// =========================
// ƒê·ªíNG B·ªò FOLDERS
// =========================


// L∆∞u folders v√†o PostgreSQL (new)
async function syncFoldersToPostgreSQL(folders, syncTimestamp = new Date()) {
  console.log('üíæ B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô folders v√†o PostgreSQL...');
  
  const syncedIds = new Set();

  if (folders.length === 0) {
    console.log('‚úÖ Kh√¥ng c√≥ folders c·∫ßn ƒë·ªìng b·ªô v√†o PostgreSQL');
  }

  try {
    // Use EasyMigrationService for PostgreSQL sync
    const EasyMigrationService = require('./src/services/EasyMigrationService');
    const migrationService = new EasyMigrationService();
    
    // Create a custom sync method that doesn't truncate (for incremental updates)
    const { pool } = require('./src/db');
    const client = await pool.connect();
    
    try {
      await client.query('BEGIN');
      
      // Insert root folder first if needed
      const rootFolderId = config.googleDrive.rootFolderId;
      if (rootFolderId) {
        const rootQuery = `
          INSERT INTO folders (id, name, parent_id, created_time, synced_at, level)
          VALUES ($1, $2, $3, $4, $5, $6)
          ON CONFLICT (id) DO UPDATE SET
            synced_at = EXCLUDED.synced_at
        `;
        
        await client.query(rootQuery, [
          rootFolderId,
          'Root Folder',
          null,
          new Date(),
          syncTimestamp,
          0
        ]);

        syncedIds.add(rootFolderId);
      }
      
      let syncedCount = 0;
      
      // Sync all folders with upsert
      for (const folder of folders) {
        const query = `
          INSERT INTO folders (id, name, parent_id, created_time, synced_at, updated_at)
          VALUES ($1, $2, $3, $4, $5, $6)
          ON CONFLICT (id) DO UPDATE SET
            name = EXCLUDED.name,
            parent_id = EXCLUDED.parent_id,
            synced_at = EXCLUDED.synced_at,
            updated_at = EXCLUDED.updated_at
        `;
        
        const values = [
          folder.id,
          folder.name,
          folder.parents?.[0] || null,
          folder.createdTime ? new Date(folder.createdTime) : null,
          syncTimestamp,
          syncTimestamp
        ];
        
        await client.query(query, values);
        syncedCount++;
        syncedIds.add(folder.id);
      }
      
      await client.query('COMMIT');
      console.log(`‚úÖ Ho√†n th√†nh ƒë·ªìng b·ªô ${syncedCount} folders v√†o PostgreSQL`);
      
      return { syncedCount, syncedIds: Array.from(syncedIds) };
      
    } catch (error) {
      await client.query('ROLLBACK');
      throw error;
    } finally {
      client.release();
    }
    
  } catch (error) {
    console.error('‚ùå L·ªói ƒë·ªìng b·ªô PostgreSQL:', error);
    throw error;
  }
}

// =========================
// ƒê·ªíNG B·ªò ·∫¢NH V√ÄO POSTGRESQL
// =========================

// ƒê·ªìng b·ªô ·∫£nh v√†o b·∫£ng images PostgreSQL
async function syncImagesToPostgreSQL(images, syncTimestamp = new Date()) {
  console.log(`üíæ B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô ${images.length} ·∫£nh v√†o PostgreSQL...`);
  
  if (images.length === 0) {
    console.log('üìù Kh√¥ng c√≥ ·∫£nh n√†o c·∫ßn ƒë·ªìng b·ªô');
    return { successCount: 0, errorCount: 0, syncedIds: [] };
  }
  
  const { pool } = require('./src/db');
  const client = await pool.connect();
  
  try {
    let successCount = 0;
    let errorCount = 0;
    const syncedIds = [];
    
    for (const image of images) {
      try {
        await client.query(`
          INSERT INTO images (id, name, created_time, parents, mime_type, thumbnail_link, last_synced_at)
          VALUES ($1, $2, $3, $4, $5, $6, $7)
          ON CONFLICT (id) DO UPDATE SET
            name = EXCLUDED.name,
            created_time = EXCLUDED.created_time,
            parents = EXCLUDED.parents,
            mime_type = EXCLUDED.mime_type,
            thumbnail_link = EXCLUDED.thumbnail_link,
            last_synced_at = $7
        `, [
          image.id,
          image.name,
          image.createdTime,
          JSON.stringify(image.parents || []),
          image.mimeType,
          image.thumbnailLink,
          syncTimestamp
        ]);
        
        successCount++;
        syncedIds.push(image.id);
        
        // Log progress every 1000 images
        if (successCount % 1000 === 0) {
          console.log(`üìä ƒê√£ ƒë·ªìng b·ªô ${successCount}/${images.length} ·∫£nh...`);
        }
        
      } catch (imageError) {
        errorCount++;
        console.error(`‚ùå L·ªói ƒë·ªìng b·ªô ·∫£nh ${image.id}:`, imageError.message);
      }
    }
    
    console.log(`‚úÖ Ho√†n th√†nh ƒë·ªìng b·ªô ·∫£nh v√†o PostgreSQL:`);
    console.log(`   - ‚úÖ Th√†nh c√¥ng: ${successCount} ·∫£nh`);
    console.log(`   - ‚ùå L·ªói: ${errorCount} ·∫£nh`);
    
    return { successCount, errorCount, syncedIds };
    
  } catch (error) {
    console.error('‚ùå L·ªói trong qu√° tr√¨nh ƒë·ªìng b·ªô ·∫£nh:', error);
    throw error;
  } finally {
    client.release();
  }
}

// =========================
// C·∫¨P NH·∫¨T MANIFEST V·ªöI ·∫¢NH M·ªöI
// =========================



// =========================
// C·∫¨P NH·∫¨T SYSTEM STATE
// =========================

async function updateSystemState(totalImages, newImagesCount = 0, totalFolders = 0) {
  console.log('üìä [Worker] Updating system state to PostgreSQL...');
  
  try {
    // Update PostgreSQL only
    await SystemStateService.updateDocument('manifest_state', {
      totalImages,
      totalFolders,
      newImagesAdded: newImagesCount,
      lastProcessed: new Date().toISOString(),
      status: 'processed',
      version: '1.0'
    });
    
    console.log(`‚úÖ [Worker] PostgreSQL system state updated: ${totalImages} images, ${totalFolders} folders (${newImagesCount} new images)`);
    
  } catch (error) {
    console.error('‚ùå [Worker] Error updating system state to PostgreSQL:', error);
    throw error;
  }
}

// =========================
// H√ÄM CH√çNH - ƒê·ªíNG B·ªò HO√ÄN CH·ªàNH
// =========================

async function processCompleteSync(forceFullScan = false) {
  try {
    // Optional hard reset: clear images table before syncing
    const resetImages = process.argv.includes('--reset-images');
    if (resetImages) {
      console.log('‚ö†Ô∏è  Reset mode enabled: clearing images table before full sync...');
      await resetImagesTable();
    }
    if (forceFullScan) {
      console.log('üöÄ B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô HO√ÄN TO√ÄN (Qu√©t l·∫°i to√†n b·ªô)...');
    } else {
      console.log('üöÄ B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô ho√†n ch·ªânh (Folders + Images)...');
    }
    console.log('üìÖ Th·ªùi gian b·∫Øt ƒë·∫ßu:', new Date().toISOString());
    console.log('üìÅ Root Folder ID:', ROOT_FOLDER_ID);

    // B∆Ø·ªöC 1: L·∫•y th·ªùi gian c·∫≠p nh·∫≠t cu·ªëi
    console.log('\n=== B∆Ø·ªöC 1: L·∫§Y TH·ªúI GIAN C·∫¨P NH·∫¨T CU·ªêI ===');
    const lastUpdateTime = forceFullScan ? new Date(0) : await getLastUpdateTime();
    if (forceFullScan) {
      console.log('üìÖ Ch·∫ø ƒë·ªô qu√©t to√†n b·ªô: B·ªè qua th·ªùi gian c·∫≠p nh·∫≠t');
    } else {
      console.log('üìÖ Th·ªùi gian c·∫≠p nh·∫≠t cu·ªëi:', lastUpdateTime.toISOString());
    }

    // B∆Ø·ªöC 2: Qu√©t to√†n b·ªô Drive (folders + images)
    console.log('\n=== B∆Ø·ªöC 2: QU√âT TO√ÄN B·ªò DRIVE ===');
    const { allFolders, allImages } = await scanDriveComplete(lastUpdateTime, forceFullScan);

    // B∆Ø·ªöC 3: ƒê·ªìng b·ªô folders v√†o PostgreSQL
    console.log('\n=== B∆Ø·ªöC 3: ƒê·ªíNG B·ªò FOLDERS ===');
    
    // Sync to PostgreSQL only
    const folderSyncTimestamp = new Date();
    const folderSyncResult = await syncFoldersToPostgreSQL(allFolders, folderSyncTimestamp);

    if (forceFullScan) {
      const folderIds = folderSyncResult?.syncedIds || [];
      await cleanupMissingFolders(folderIds);
    }

    // B∆Ø·ªöC 4: ƒê·ªìng b·ªô ·∫£nh v√†o PostgreSQL
    if (forceFullScan || allImages.length > 0) {
      console.log('\n=== B∆Ø·ªöC 4: ƒê·ªíNG B·ªò ·∫¢NH V√ÄO POSTGRESQL ===');
      
      if (forceFullScan) {
        // Ch·∫ø ƒë·ªô qu√©t to√†n b·ªô: ƒê·ªìng b·ªô t·∫•t c·∫£ ·∫£nh
        console.log(`üìä Qu√©t to√†n b·ªô: ƒê·ªìng b·ªô ${allImages.length} ·∫£nh v√†o PostgreSQL`);
        const imageSyncTimestamp = new Date();
        const imageSyncResult = await syncImagesToPostgreSQL(allImages, imageSyncTimestamp);

        if (forceFullScan) {
          if (imageSyncResult.errorCount > 0) {
            console.warn('‚ö†Ô∏è  B·ªè qua b∆∞·ªõc d·ªçn ·∫£nh v√¨ c√≥ l·ªói khi ƒë·ªìng b·ªô, tr√°nh xo√° nh·∫ßm d·ªØ li·ªáu.');
          } else {
            await cleanupMissingImages(imageSyncResult.syncedIds || []);
          }
        }
      } else {
        // Ch·∫ø ƒë·ªô qu√©t ·∫£nh m·ªõi: Ch·ªâ ƒë·ªìng b·ªô ·∫£nh m·ªõi
        console.log(`üìä ƒê·ªìng b·ªô ${allImages.length} ·∫£nh m·ªõi v√†o PostgreSQL`);
        await syncImagesToPostgreSQL(allImages);
      }
    } else {
      console.log('\n=== B∆Ø·ªöC 4: KH√îNG C√ì ·∫¢NH M·ªöI ===');
      console.log('‚úÖ Kh√¥ng c√≥ ·∫£nh m·ªõi n√†o c·∫ßn c·∫≠p nh·∫≠t');
    }

    // B∆Ø·ªöC 5: C·∫≠p nh·∫≠t system state
    console.log('\n=== B∆Ø·ªöC 5: C·∫¨P NH·∫¨T SYSTEM STATE ===');
    if (forceFullScan) {
      await updateSystemState(allImages.length, allImages.length, allFolders.length);
    } else {
      // L·∫•y t·ªïng s·ªë ·∫£nh t·ª´ PostgreSQL thay v√¨ Firestore
      const { pool } = require('./src/db');
      const client = await pool.connect();
      try {
        const result = await client.query('SELECT COUNT(*) as total FROM images');
        const totalImages = parseInt(result.rows[0].total);
        await updateSystemState(totalImages, allImages.length, allFolders.length);
      } finally {
        client.release();
      }
    }

    // B∆Ø·ªöC 6: C·∫≠p nh·∫≠t folder image counts t·ª´ PostgreSQL
    console.log('\n=== B∆Ø·ªöC 6: C·∫¨P NH·∫¨T FOLDER IMAGE COUNTS ===');
    await updateFolderImageCountsFromPostgreSQL();

    console.log('\nüéâ HO√ÄN TH√ÄNH ƒê·ªíNG B·ªò HO√ÄN CH·ªàNH!');
    console.log(`üìä T·ªïng k·∫øt:`);
    console.log(`   - üìÅ Folders: ${allFolders.length}`);
    if (forceFullScan) {
      console.log(`   - üñºÔ∏è T·ªïng ·∫£nh: ${allImages.length}`);
      console.log(`   - üîÑ Ch·∫ø ƒë·ªô: Qu√©t to√†n b·ªô`);
    } else {
      // L·∫•y t·ªïng s·ªë ·∫£nh t·ª´ PostgreSQL
      const { pool } = require('./src/db');
      const client = await pool.connect();
      try {
        const result = await client.query('SELECT COUNT(*) as total FROM images');
        const totalImages = parseInt(result.rows[0].total);
        console.log(`   - üñºÔ∏è ·∫¢nh m·ªõi: ${allImages.length}`);
        console.log(`   - üñºÔ∏è T·ªïng ·∫£nh: ${totalImages}`);
        console.log(`   - üîÑ Ch·∫ø ƒë·ªô: Qu√©t ·∫£nh m·ªõi`);
      } finally {
        client.release();
      }
    }
    console.log(`   - ‚è∞ Th·ªùi gian ho√†n th√†nh: ${new Date().toISOString()}`);

  } catch (error) {
    console.error('‚ùå L·ªói trong qu√° tr√¨nh ƒë·ªìng b·ªô ho√†n ch·ªânh:', error);
    throw error;
  }
}

// =========================
// MAIN FUNCTION
// =========================

async function main() {
  try {
    // Ki·ªÉm tra argument ƒë·ªÉ quy·∫øt ƒë·ªãnh ch·∫ø ƒë·ªô qu√©t
    const forceFullScan = process.argv.includes('--full-scan') || process.argv.includes('--reset');
    
    if (forceFullScan) {
      console.log('üöÄ Manifest Worker - Ch·∫ø ƒë·ªô QU√âT TO√ÄN B·ªò (Reset ho√†n to√†n)');
    } else {
      console.log('üöÄ Manifest Worker - ƒê·ªìng b·ªô ho√†n ch·ªânh (Folders + Images)');
    }
    console.log('üìÅ Root Folder ID:', ROOT_FOLDER_ID);
    console.log('üîß Chunk Size:', CHUNK_SIZE);
    console.log('üìè Max Document Size:', (MAX_DOCUMENT_SIZE / 1024).toFixed(2), 'KB');
    if (forceFullScan) {
      console.log('üîÑ Ch·∫ø ƒë·ªô: Qu√©t to√†n b·ªô (b·ªè qua manifest c≈©)');
    }
    console.log('');

    await processCompleteSync(forceFullScan);
    
    console.log('\n‚úÖ Worker ho√†n th√†nh th√†nh c√¥ng!');
    process.exit(0);
    
  } catch (error) {
    console.error('\n‚ùå Worker th·∫•t b·∫°i:', error);
    process.exit(1);
  }
}

// Ch·∫°y worker n·∫øu ƒë∆∞·ª£c g·ªçi tr·ª±c ti·∫øp
if (require.main === module) {
  main();
}


// C·∫≠p nh·∫≠t folder image counts t·ª´ b·∫£ng images PostgreSQL
async function updateFolderImageCountsFromPostgreSQL() {
  console.log('üìä [Worker] Updating folder image counts from PostgreSQL...');
  
  try {
    const { pool } = require('./src/db');
    const client = await pool.connect();
    
    try {
      // ƒê·∫øm ·∫£nh theo folder t·ª´ b·∫£ng images
      const result = await client.query(`
        SELECT 
          jsonb_array_elements_text(parents) as folder_id,
          COUNT(DISTINCT id) as image_count
        FROM images 
        WHERE parents IS NOT NULL AND parents != '[]'::jsonb
        GROUP BY jsonb_array_elements_text(parents)
      `);
      
      console.log(`üìä Found ${result.rows.length} folders with images`);
      
      let updatedCount = 0;
      
      // C·∫≠p nh·∫≠t image_count cho t·ª´ng folder
      for (const row of result.rows) {
        const folderId = row.folder_id;
        const imageCount = parseInt(row.image_count);
        
        const updateResult = await client.query(`
          UPDATE folders 
          SET image_count = $1, updated_at = NOW()
          WHERE id = $2
        `, [imageCount, folderId]);
        
        if (updateResult.rowCount > 0) {
          updatedCount++;
          console.log(`  üìÅ ${folderId}: ${imageCount} images`);
        }
      }
      
      // Reset count cho folders kh√¥ng c√≥ ·∫£nh
      const resetResult = await client.query(`
        UPDATE folders 
        SET image_count = 0, updated_at = NOW()
        WHERE id NOT IN (
          SELECT DISTINCT jsonb_array_elements_text(parents) 
          FROM images 
          WHERE parents IS NOT NULL AND parents != '[]'::jsonb
        )
        AND image_count > 0
      `);
      
      console.log(`‚úÖ Updated ${updatedCount} folders with image counts`);
      console.log(`üîÑ Reset ${resetResult.rowCount} folders to 0 images`);
      
    } finally {
      client.release();
    }
    
  } catch (error) {
    console.error('‚ùå Error updating folder image counts:', error);
    // Don't throw - this is not critical
  }
}

// Export functions ƒë·ªÉ test/module usage
module.exports = {
  processCompleteSync,
  syncImagesToPostgreSQL,
  updateSystemState,
  scanDriveComplete,
  syncFoldersToPostgreSQL,
  updateFolderImageCountsFromPostgreSQL,
  listByQuery,
  cleanupMissingFolders,
  cleanupMissingImages
};

// Helper: hard reset images table (use with --reset-images)
async function resetImagesTable() {
  try {
    const { pool } = require('./src/db');
    const client = await pool.connect();
    try {
      console.log('üßπ Deleting all rows from images...');
      await client.query('DELETE FROM images');
      console.log('‚úÖ Images table cleared');
    } finally {
      client.release();
    }
  } catch (error) {
    console.error('‚ùå Error clearing images table:', error);
    throw error;
  }
}

// Helper: hard reset folders table (use with full scan)
async function resetFoldersTable() {
  try {
    const { pool } = require('./src/db');
    const client = await pool.connect();
    try {
      console.log('üßπ Deleting all rows from folders...');
      await client.query('TRUNCATE TABLE folders CASCADE');
      console.log('‚úÖ Folders table cleared');
    } finally {
      client.release();
    }
  } catch (error) {
    console.error('‚ùå Error clearing folders table:', error);
    throw error;
  }
}

async function cleanupMissingFolders(validFolderIds = []) {
  console.log('üßπ [Worker] Cleaning up folders missing from Drive snapshot...');

  try {
    const { pool } = require('./src/db');
    const client = await pool.connect();

    try {
      const ids = Array.from(new Set(validFolderIds.filter(Boolean)));
      let result;

      if (ids.length === 0) {
        result = await client.query('DELETE FROM folders');
      } else {
        result = await client.query(`
          DELETE FROM folders
          WHERE NOT (id = ANY($1::text[]))
        `, [ids]);
      }

      if (result.rowCount > 0) {
        console.log(`‚úÖ Removed ${result.rowCount} folders that are no longer in Drive`);
      } else {
        console.log('‚úÖ No folders removed during cleanup');
      }

    } finally {
      client.release();
    }

  } catch (error) {
    console.error('‚ùå Error cleaning up folders:', error);
    throw error;
  }
}

async function cleanupMissingImages(validImageIds = []) {
  console.log('üßπ [Worker] Cleaning up images missing from Drive snapshot...');

  try {
    const { pool } = require('./src/db');
    const client = await pool.connect();

    try {
      const ids = Array.from(new Set(validImageIds.filter(Boolean)));
      let result;

      if (ids.length === 0) {
        result = await client.query('DELETE FROM images');
      } else {
        result = await client.query(`
          DELETE FROM images
          WHERE NOT (id = ANY($1::text[]))
        `, [ids]);
      }

      if (result.rowCount > 0) {
        console.log(`‚úÖ Removed ${result.rowCount} images that are no longer in Drive`);
      } else {
        console.log('‚úÖ No images removed during cleanup');
      }

    } finally {
      client.release();
    }

  } catch (error) {
    console.error('‚ùå Error cleaning up images:', error);
    throw error;
  }
}
